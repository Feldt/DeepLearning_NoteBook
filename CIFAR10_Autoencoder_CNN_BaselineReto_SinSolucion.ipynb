{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Feldt/DeepLearning_NoteBook/blob/main/CIFAR10_Autoencoder_CNN_BaselineReto_SinSolucion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVM7YqFuQdmQ"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras import datasets, layers, models\n",
        "from keras import regularizers\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIPvOkVEOxL4"
      },
      "source": [
        "Cargar el dataset cifar10 en un conjunto inicial de training (imagenes y labels) y test (imágenes y labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URm8pbI0TzDE"
      },
      "outputs": [],
      "source": [
        "(x_train0, y_train0), (x_test0, y_test0) = datasets.cifar10.load_data()\n",
        "\n",
        "print(f\"Forma del conjunto de entrenamiento: {x_train0.shape}\")\n",
        "print(f\"Forma del conjunto de prueba: {x_test0.shape}\")\n",
        "print(f\"Rango de valores originales: {x_train0.min()} - {x_train0.max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnNtIWM2QlYn"
      },
      "outputs": [],
      "source": [
        "# lista de etiquetas CIFAR10\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67vriW48PtnF"
      },
      "source": [
        "### 1. Pre-procesamiento del dataset\n",
        "\n",
        "a. Convierte los pixeles de las imágenes del conjunto de train y test a tipo float\n",
        "\n",
        "b. Normaliza, dividiendo el valor de todos los pixeles por 255, ya que es el valor máximo de intensidad de cada pixel.\n",
        "\n",
        "c. Codifica las etiquetas y_train y y_test como one-hot utilizando la funcion to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS8WKQk-Qrge"
      },
      "outputs": [],
      "source": [
        "# Convierte los pixeles de las imágenes del conjunto de train y test a tipo float\n",
        "x_train = x_train0.astype('float32')\n",
        "x_test = x_test0.astype('float32')\n",
        "\n",
        "print(f\"Despues de conversion a float32:\")\n",
        "print(f\"x_train dtype: {x_train.dtype}\")\n",
        "print(f\"x_test dtype: {x_test.dtype}\")\n",
        "\n",
        "# dividiendo el valor de todos los pixeles por 255, ya que es el valor máximo de intensidad de cada pixel.\n",
        "x_train  = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "print(f\"Despues de normalizacion:\")\n",
        "print(f\"Rango x_train: {x_train.min()} - {x_train.max()}\")\n",
        "print(f\"Rango x_test: {x_test.min()} - {x_test.max()}\")\n",
        "\n",
        "\n",
        "# Codificar las etiquetas y_train y y_test como one-hot utilizando la funcion to_categorical\n",
        "y_train = keras.utils.to_categorical(y_train0, 10)\n",
        "y_test = keras.utils.to_categorical(y_test0,10)\n",
        "\n",
        "print(f\"Forma de etiquetas one-hot:\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "345zUigMP6-I"
      },
      "source": [
        "Dividimos el test set en 7000 imagenes de validacion (x_val_images) y 3000 de test set (x_test_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGDrLp3SYkeN"
      },
      "outputs": [],
      "source": [
        "# Renombrar por claridad\n",
        "x_train_images = x_train\n",
        "x_test_images = x_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTkHv176aPmx"
      },
      "outputs": [],
      "source": [
        "# Dividir test en validacion y test, 7000 de validacion y 3000 de test\n",
        "x_val_images = x_test_images[:7000]\n",
        "x_test_images = x_test_images[7000:]\n",
        "\n",
        "print(f\"Division de conjuntos:\")\n",
        "print(f\"Training: {x_train_images.shape}\")\n",
        "print(f\"Validation: {x_val_images.shape}\")\n",
        "print(f\"Test: {x_test_images.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuQEuzYKQHtl"
      },
      "source": [
        "Dividimos las etiquetas de validacion (y_val y y_test) de tal forma que correspondan a los conjuntos previos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJCXIw32QLE7"
      },
      "outputs": [],
      "source": [
        "# Dividir etiquetas de validacion\n",
        "y_val_labels = y_test[:7000]\n",
        "y_test_labels = y_test[7000:]\n",
        "\n",
        "print(f\"Division de etiquetas:\")\n",
        "print(f\"Training labels: {y_train.shape}\")\n",
        "print(f\"Validation labels: {y_val_labels.shape}\")\n",
        "print(f\"Test labels: {y_test_labels.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk-3fPqmQNkT"
      },
      "outputs": [],
      "source": [
        "# Algunos imports complementarios\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Add, Concatenate, Conv2D, Conv2DTranspose, UpSampling2D, MaxPooling2D, MaxPool2D, Flatten, BatchNormalization\n",
        "import keras.backend as K\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3R55IXPXZCE"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Modelo encoder-decoder de referencia\n",
        "\n",
        "print(\"=== CONSTRUYENDO MODELO ===\")\n",
        "\n",
        "\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Red encoder\n",
        "x = Conv2D(64, (3, 3), padding='same')(input_img)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "print(f\"Forma del encoded: {encoded.shape}\")\n",
        "\n",
        "\n",
        "# Red decoder\n",
        "x = Conv2D(16, (3, 3), padding='same')(encoded)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(3, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "decoded = Activation('sigmoid')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "615q9rKZRbJu"
      },
      "outputs": [],
      "source": [
        "# Modelo Encoder-Decoder\n",
        "model = Model(input_img, decoded)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oAcGbsUEbys"
      },
      "source": [
        "### 2. Entrenamiento de autoencoder\n",
        "\n",
        "a. Entrena el modelo no-supervisado encoder-decoder de tal forma que el modelo aprenda a reconstruir su propio input, con batch_size 64, mínimo 20 épocas.\n",
        "\n",
        "b. Investiga e implementa el uso de los callbacks de EarlyStopping y ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nV8scCPQjkh"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "print(\"=== ENTRENANDO MODELO BASELINE ===\")\n",
        "\n",
        "# Callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_autoencoder.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "history = model.fit(x_train_images, x_train_images,\n",
        "                    epochs=20,\n",
        "                    batch_size=64,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(x_val_images, x_val_images),\n",
        "                    callbacks=[early_stop, checkpoint])\n",
        "\n",
        "print(f\"Training final loss: {history.history['loss'][-1]:.4f}\")\n",
        "print(f\"Validation final loss: {history.history['val_loss'][-1]:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fge6U-PJWTRa"
      },
      "source": [
        "c. Visualización del proceso de entrenamiento. Grafica Training Loss vs. Validation Loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVwViUKCQ9x3"
      },
      "outputs": [],
      "source": [
        "# Gráfica de Training Loss vs Validation Loss\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epoca')\n",
        "plt.ylabel('Perdida (Loss)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hzHkn23W2Sq"
      },
      "source": [
        "d. Visualización del input reconstruido\n",
        "\n",
        "Imprime un conjunto de imágenes originales y comparalas con la imagen reconstruida por el autoencoder.\n",
        "\n",
        "Utiliza las siguientes funciones de referencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRWHe1haWKZg"
      },
      "outputs": [],
      "source": [
        "c10test = model.predict(x_test_images)\n",
        "c10val = model.predict(x_val_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WTicX_pWyfp"
      },
      "outputs": [],
      "source": [
        "# Funcion para mostrar imagenes originales y reconstruidas\n",
        "\n",
        "def showOrigDec(orig, dec, num=10):\n",
        "    import matplotlib.pyplot as plt\n",
        "    n = num\n",
        "    plt.figure(figsize=(20, 4))\n",
        "\n",
        "    for i in range(n):\n",
        "        # original\n",
        "        ax = plt.subplot(2, n, i+1)\n",
        "        plt.imshow(orig[i].reshape(32, 32, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # reconstruidas\n",
        "        ax = plt.subplot(2, n, i +1 + n)\n",
        "        plt.imshow(dec[i].reshape(32, 32, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kc6xFbYYfj3"
      },
      "outputs": [],
      "source": [
        "# Muestra algunas imagenes originales y reconstruidas utilizando tu funcion\n",
        "showOrigDec(x_test_images, c10test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQugJj1oSnr8"
      },
      "source": [
        "A continuación generaremos el modelo encoder del autoencoder. Este modelo lo utilizarás para obtener la representación codificada de los conjuntos originales y con ella entrenar un clasificador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdNt44SYHIws"
      },
      "outputs": [],
      "source": [
        "# Modelo Encoder\n",
        "encoder = Model(input_img, encoded)\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAta3hUdReZR"
      },
      "source": [
        "### 3. Extracción de features del autoencoder\n",
        "\n",
        "Utilizando el **método predict del modelo encoder** extrae las variables que te indicamos a continuación:\n",
        "\n",
        "a. Codifica el el conjunto de imágenes de entrenamiento utilizando el método predict del encoder, y guárdalo en una variable llamada **gist_train_ae**\n",
        "\n",
        "b. Codifica el conjunto de imágenes de validación, utilizando el método predict del encoder y guárdalo en una variable llamada **gist_valid_ae**\n",
        "\n",
        "c. Codifica el conjunto de imágenes de prueba utilizando el método predict del encoder y guárdalo en una variable llamada **gist_test_ae**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcI-cTqQZGzT"
      },
      "outputs": [],
      "source": [
        "# Completa esta función...\n",
        "print(\"=== EXTRAYENDO FEATURES \")\n",
        "gist_train_ae = encoder.predict(x_train_images)\n",
        "gist_valid_ae = encoder.predict(x_val_images)\n",
        "gist_test_ae = encoder.predict(x_test_images)\n",
        "\n",
        "\n",
        "print(f\"Forma de features extraídas (baseline):\")\n",
        "print(f\"gist_train_ae: {gist_train_ae.shape}\")\n",
        "print(f\"gist_valid_ae: {gist_valid_ae.shape}\")\n",
        "print(f\"gist_test_ae: {gist_test_ae.shape}\")\n",
        "\n",
        "print(f\"Rango de valores en features:\")\n",
        "print(f\"Train features: {gist_train_ae.min():.4f} - {gist_train_ae.max():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NyTrHuiJRmb"
      },
      "source": [
        "A continuación definimos un clasificador con una capa convolucional y dos capas densas, que aprenderá a clasificar el input una vez procesado por el codificador.\n",
        "\n",
        "Puedes utilizar el siguiente clasificador como referencia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gntlowXWYjym"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "input = Input((gist_train_ae.shape[1], gist_train_ae.shape[2], gist_train_ae.shape[3]))\n",
        "\n",
        "x = Conv2D(64, 3, padding=\"same\")(input)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(2)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "decoder_classifier = Model(input, output)\n",
        "decoder_classifier.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['acc'])\n",
        "decoder_classifier.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg0NF2GxZK-4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LALau4YR6MXz"
      },
      "source": [
        "### 4. Entrenamiento y evaluación del clasificador\n",
        "\n",
        "a. Entrena el clasificador **decoder_classifier** definido en la fase previa utilizando como input la representación codificada del training set obtenida en el paso previo y como output los labels originales del conjunto de training.\n",
        "\n",
        "b. Calcula la pérdida de validación del modelo, utilizando la representación codificada de los datos de validación y como ouput los labels originales del conjunto de validación.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfyaKfN42W7U"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"=== ENTRENANDO CLASIFICADOR ===\")\n",
        "early_stop_clf = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "checkpoint_clf = ModelCheckpoint('best_decoder_classifier.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "callbacks = [early_stop_clf, checkpoint_clf]\n",
        "\n",
        "history_clf = decoder_classifier.fit(gist_train_ae, y_train,\n",
        "                       validation_data=(gist_valid_ae, y_val_labels),\n",
        "                       batch_size=64, epochs=20, callbacks=callbacks)\n",
        "\n",
        "print(f\"Classifier - Final training accuracy: {history_clf.history['acc'][-1]:.4f}\")\n",
        "print(f\"Classifier - Final validation accuracy: {history_clf.history['val_acc'][-1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hapDlY5xTL8-"
      },
      "source": [
        "c. Genera predicciones con el modelo clasificador, utiliza el conjunto de test codificado modelo encoder. Guárdalo en la variable pred.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVbIsCaB-_OR"
      },
      "outputs": [],
      "source": [
        "# Obtener las etiquetas con el clasificador\n",
        "pred = decoder_classifier.predict(gist_test_ae)\n",
        "\n",
        "# Convertimos las predicciones a una lista de etiquetas única\n",
        "pred_classes = np.argmax(pred, axis=1)\n",
        "print(pred_classes)\n",
        "\n",
        "print(\"=== RESULTADOS  ===\")\n",
        "print(f\"Forma de predicciones: {pred.shape}\")\n",
        "print(f\"Primeras 10 predicciones (clases): {pred_classes[:10]}\")\n",
        "print(f\"Primeras 10 etiquetas reales: {np.argmax(y_test_labels[:10], axis=1)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIP23LYiR7an"
      },
      "source": [
        "d. Evalúa las predicciones del modelo y obten la matriz de confusión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnhIsKSW8MA4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(np.argmax(y_test_labels, axis=1), pred_classes)\n",
        "accuracy = accuracy_score(np.argmax(y_test_labels, axis=1), pred_classes)\n",
        "\n",
        "print(\"Matriz de confusion:\\n\")\n",
        "print(cm)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(\"Classification Report:\\n\")\n",
        "cr=classification_report(y_test_labels.argmax(axis=1), pred.argmax(axis=1), target_names=class_names)\n",
        "print(cr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNfnSotBaTit"
      },
      "source": [
        "### 5. Mejoras a los modelos\n",
        "\n",
        "Aplicando los conceptos del curso modifica dichas redes para obtener un mejor accuracy ¿Crees poder lograr un 70% o tal vez 80% de accuracy con tu modelo? OJO: NO está permitido modificar el modelo clasificador.\n",
        "\n",
        "a.    Experimenta agregando capas, modificando operaciones y modificando las dimensiones de las capas actuales. OJO: Recuerda que para que tu modelo encoder-decoder siga funcionando y puedas reconstruir las imágenes codificadas, las capas de MaxPool del encoder deben de corresponder a las capas UpSample del decoder. Tip: ¿Las capas de pooling ayudan o perjudican a tu modelo?\n",
        "\n",
        "\n",
        "b.    En una celda de texto, justifica los cambios realizados, a la arquitectura.\n",
        "\n",
        "\n",
        "c.     Genera la matriz de confusión de tu ensamble de modelos mejorado. Recuerda que debes re-entrenar el clasificador si la arquitectura del autoencoder cambia.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#MEJORAS IMPLEMENTADAS\n",
        "\n",
        "---\n",
        "\n",
        "##1. AUTOENCODER:\n",
        "   - Capas adicionales en cada bloque (64-64, 128-128, 256-256)\n",
        "   - Skip connections para preservar información\n",
        "   - Bottleneck más informativo (8x8x128)\n",
        "   - Misma normalización que baseline  \n",
        "\n",
        "## 2. CLASIFICADOR:\n",
        "   - Más filtros iniciales (128 vs 64)\n",
        "   - Capas adicionales en parte convolucional\n",
        "   - Red densa más profunda (256->128->10)\n",
        "   - Dropout moderado (0.25, 0.4)  \n",
        "\n",
        "## 3. ENTRENAMIENTO:\n",
        "   - Ligeramente más epochs (35 vs 30)\n",
        "   - Mismos hiperparámetros base que funcionan\n",
        "   - Early stopping conservador\n"
      ],
      "metadata": {
        "id": "MbZ71GSWtYhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "QQKLiSsxtYKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKhhpQjW-yyr"
      },
      "outputs": [],
      "source": [
        "# MODELO - ENFOQUE CONSERVADOR Y EFECTIVO\n",
        "input_img_improved = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Encoder - cambios graduales para baseline\n",
        "x = Conv2D(64, (3, 3), padding='same')(input_img_improved)  # Sin regularizacion excesiva\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)  # Capa adicional en primer bloque\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "skip1 = x  # Skip connection\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)  # 16x16\n",
        "\n",
        "x = Conv2D(128, (3, 3), padding='same')(x)  # Incremento gradual de filtros\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "skip2 = x  # Skip connection\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)  # 8x8\n",
        "\n",
        "x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "# Bottleneck más informativo\n",
        "x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "encoded_improved = Activation('relu')(x)  # 8x8x128\n",
        "\n",
        "print(f\"Forma del encoded: {encoded_improved.shape}\")\n",
        "\n",
        "# Decoder - con skip connections\n",
        "x = Conv2D(128, (3, 3), padding='same')(encoded_improved)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D((2, 2))(x)  # 16x16\n",
        "x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "# Skip connection\n",
        "x = Add()([x, skip2])\n",
        "x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D((2, 2))(x)  # 32x32\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "# Skip connection\n",
        "x = Add()([x, skip1])\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = Conv2D(3, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "decoded_improved = Activation('sigmoid')(x)  # sigmoid para [0,1]\n",
        "\n",
        "# Modelo\n",
        "model_improved = Model(input_img_improved, decoded_improved)\n",
        "model_improved.compile(optimizer='adam', loss='mse')  # Mantenemos adam simple\n",
        "model_improved.summary()\n",
        "\n",
        "print(\"=== ENTRENANDO MODELO ===\")\n",
        "\n",
        "# Callbacks conservadores\n",
        "early_stop_improved = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "checkpoint_improved = ModelCheckpoint('best_autoencoder_improved.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "# USAR LOS MISMOS DATOS QUE LA VERSION INICIAL - NO cambia normalizacion\n",
        "x_train_normalized = x_train_images\n",
        "x_val_normalized = x_val_images\n",
        "x_test_normalized = x_test_images\n",
        "\n",
        "history_improved = model_improved.fit(x_train_normalized, x_train_normalized,\n",
        "                                    epochs=35,  # Solo un poco más que inicial\n",
        "                                    batch_size=64,  # Mismo batch size que inicial\n",
        "                                    shuffle=True,\n",
        "                                    validation_data=(x_val_normalized, x_val_normalized),\n",
        "                                    callbacks=[early_stop_improved, checkpoint_improved],\n",
        "                                    verbose=1)\n",
        "\n",
        "print(f\"Improved Training final loss: {history_improved.history['loss'][-1]:.4f}\")\n",
        "print(f\"Improved Validation final loss: {history_improved.history['val_loss'][-1]:.4f}\")\n",
        "\n",
        "# Comparacion de perdidas\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_clf.history['loss'], label='Base Training', linewidth=2)\n",
        "plt.plot(history_clf.history['val_loss'], label='Base Validation', linewidth=2)\n",
        "plt.title('Base Model Loss')\n",
        "plt.xlabel('Epoca')\n",
        "plt.ylabel('Perdida')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_improved.history['loss'], label='Improved Training', linewidth=2)\n",
        "plt.plot(history_improved.history['val_loss'], label='Improved Validation', linewidth=2)\n",
        "plt.title('Improved Model Loss')\n",
        "plt.xlabel('Epoca')\n",
        "plt.ylabel('Perdida')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Predicciones del modelo mejorado\n",
        "c10test_improved = model_improved.predict(x_test_normalized)\n",
        "c10val_improved = model_improved.predict(x_val_normalized)\n",
        "\n",
        "# Comparacion visual de reconstrucciones\n",
        "print(\"base: Original vs Reconstruida\")\n",
        "showOrigDec(x_test_images, c10test)\n",
        "print(\"Improved: Original vs Reconstruida\")\n",
        "showOrigDec(x_test_images, c10test_improved)\n",
        "\n",
        "# Encoder mejorado\n",
        "encoder_improved = Model(input_img_improved, encoded_improved)\n",
        "encoder_improved.summary()\n",
        "\n",
        "print(\"=== EXTRAYENDO FEATURES DEL MODELO MEJORADO ===\")\n",
        "\n",
        "# Extraer features\n",
        "gist_train_ae_improved = encoder_improved.predict(x_train_normalized)\n",
        "gist_valid_ae_improved = encoder_improved.predict(x_val_normalized)\n",
        "gist_test_ae_improved = encoder_improved.predict(x_test_normalized)\n",
        "\n",
        "print(f\"Forma de features extraidas (mejorado):\")\n",
        "print(f\"gist_train_ae: {gist_train_ae_improved.shape}\")\n",
        "print(f\"gist_valid_ae: {gist_valid_ae_improved.shape}\")\n",
        "print(f\"gist_test_ae: {gist_test_ae_improved.shape}\")\n",
        "\n",
        "print(f\"Rango de valores en features mejoradas:\")\n",
        "print(f\"Train features: {gist_train_ae_improved.min():.4f} - {gist_train_ae_improved.max():.4f}\")\n",
        "\n",
        "# CLASIFICADOR MEJORADO\n",
        "input_classifier_improved = Input(gist_train_ae_improved.shape[1:])\n",
        "\n",
        "# Empezar con mas filtros para features mas ricas\n",
        "x = Conv2D(128, 3, padding=\"same\")(input_classifier_improved)  # Mas filtros que base\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, 3, padding=\"same\")(x)  # Capa adicional\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(2)(x)\n",
        "x = Dropout(0.25)(x)  # Menos dropout\n",
        "\n",
        "x = Conv2D(256, 3, padding=\"same\")(x)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(2)(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)  # Mas neuronas que en base\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "x = Dense(128, activation='relu')(x)  # Capa adicional\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "decoder_classifier_improved = Model(input_classifier_improved, output)\n",
        "decoder_classifier_improved.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['acc'])\n",
        "\n",
        "print(\"=== ENTRENANDO CLASIFICADOR MEJORADO ===\")\n",
        "\n",
        "early_stop_clf_improved = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "checkpoint_clf_improved = ModelCheckpoint('best_decoder_classifier_improved.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "callbacks_improved = [early_stop_clf_improved, checkpoint_clf_improved]\n",
        "\n",
        "history_clf_improved = decoder_classifier_improved.fit(gist_train_ae_improved, y_train,\n",
        "                                                     validation_data=(gist_valid_ae_improved, y_val_labels),\n",
        "                                                     batch_size=64, epochs=30, callbacks=callbacks_improved,\n",
        "                                                     verbose=1)\n",
        "\n",
        "print(f\"Improved Classifier - Final training accuracy: {history_clf_improved.history['acc'][-1]:.4f}\")\n",
        "print(f\"Improved Classifier - Final validation accuracy: {history_clf_improved.history['val_acc'][-1]:.4f}\")\n",
        "\n",
        "# Predicciones del clasificador mejorado\n",
        "pred_improved = decoder_classifier_improved.predict(gist_test_ae_improved)\n",
        "pred_classes_improved = np.argmax(pred_improved, axis=1)\n",
        "\n",
        "print(\"=== RESULTADOS MODELO MEJORADO ===\")\n",
        "print(f\"Forma de predicciones: {pred_improved.shape}\")\n",
        "print(f\"Primeras 10 predicciones: {pred_classes_improved[:10]}\")\n",
        "\n",
        "# Evaluacion del modelo mejorado\n",
        "cm_improved = confusion_matrix(np.argmax(y_test_labels, axis=1), pred_classes_improved)\n",
        "accuracy_improved = accuracy_score(np.argmax(y_test_labels, axis=1), pred_classes_improved)\n",
        "\n",
        "print(\"=== MATRIZ DE CONFUSIÓN MODELO MEJORADO ===\")\n",
        "print(cm_improved)\n",
        "print(f\"\\nAccuracy Mejorado: {accuracy_improved:.4f} ({accuracy_improved*100:.2f}%)\")\n",
        "print(\"\\n=== CLASSIFICATION REPORT MODELO MEJORADO ===\")\n",
        "cr_improved = classification_report(y_test_labels.argmax(axis=1), pred_improved.argmax(axis=1), target_names=class_names)\n",
        "print(cr_improved)\n",
        "\n",
        "# Comparación final de resultados\n",
        "print(\"=\"*60)\n",
        "print(\"COMPARACIoN FINAL DE RESULTADOS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"MODELO BASE:\")\n",
        "print(f\"  - Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"  - Final training loss: {history.history['loss'][-1]:.4f}\")\n",
        "print(f\"  - Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n",
        "print(f\"  - Classifier val accuracy: {history_clf.history['val_acc'][-1]:.4f}\")\n",
        "\n",
        "print(f\"\\nIMPROVED MODEL:\")\n",
        "print(f\"  - Accuracy: {accuracy_improved:.4f} ({accuracy_improved*100:.2f}%)\")\n",
        "print(f\"  - Final training loss: {history_improved.history['loss'][-1]:.4f}\")\n",
        "print(f\"  - Final validation loss: {history_improved.history['val_loss'][-1]:.4f}\")\n",
        "print(f\"  - Classifier val accuracy: {history_clf_improved.history['val_acc'][-1]:.4f}\")\n",
        "\n",
        "mejora_absoluta = (accuracy_improved - accuracy) * 100\n",
        "mejora_relativa = ((accuracy_improved - accuracy) / accuracy) * 100\n",
        "\n",
        "print(f\"\\nMEJORA ABSOLUTA: {mejora_absoluta:.2f} puntos porcentuales\")\n",
        "print(f\"MEJORA RELATIVA: {mejora_relativa:.2f}%\")\n",
        "\n",
        "# Visualización de accuracies del clasificador\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_clf.history['acc'], label='Training Accuracy', linewidth=2)\n",
        "plt.plot(history_clf.history['val_acc'], label='Validation Accuracy', linewidth=2)\n",
        "plt.title(f'Accuracy del Clasificador Base\\nFinal Test: {accuracy:.3f}')\n",
        "plt.xlabel('Epoca')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_clf_improved.history['acc'], label='Training Accuracy', linewidth=2)\n",
        "plt.plot(history_clf_improved.history['val_acc'], label='Validation Accuracy', linewidth=2)\n",
        "plt.title(f'Accuracy del Improved Classificador\\nFinal Test: {accuracy_improved:.3f}')\n",
        "plt.xlabel('Epoca')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Matriz de confusion visual\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# matrix de confusion para caso base\n",
        "im1 = ax1.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "ax1.set_title(f'Matrix de confusion para caso basen\\nAccuracy: {accuracy:.3f}')\n",
        "ax1.set_xlabel('Predicted Label')\n",
        "ax1.set_ylabel('True Label')\n",
        "ax1.set_xticks(range(10))\n",
        "ax1.set_yticks(range(10))\n",
        "ax1.set_xticklabels(class_names, rotation=45)\n",
        "ax1.set_yticklabels(class_names)\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        text = ax1.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > cm.max()/2 else \"black\")\n",
        "\n",
        "# # matrix de confusion improved\n",
        "im2 = ax2.imshow(cm_improved, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "ax2.set_title(f'Matrix de confusion Improved \\nAccuracy: {accuracy_improved:.3f}')\n",
        "ax2.set_xlabel('Predicted Label')\n",
        "ax2.set_ylabel('True Label')\n",
        "ax2.set_xticks(range(10))\n",
        "ax2.set_yticks(range(10))\n",
        "ax2.set_xticklabels(class_names, rotation=45)\n",
        "ax2.set_yticklabels(class_names)\n",
        "\n",
        "# improved\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        text = ax2.text(j, i, cm_improved[i, j], ha=\"center\", va=\"center\", color=\"white\" if cm_improved[i, j] > cm_improved.max()/2 else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Analisis de cuales clases mejoraron mas\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANALISIS POR CLASE - MEJORAS ESPECIFICAS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Metricas por clase\n",
        "precision_base, recall_base, f1_base, support_base = precision_recall_fscore_support(\n",
        "    np.argmax(y_test_labels, axis=1), pred_classes, average=None)\n",
        "\n",
        "precision_imp, recall_imp, f1_imp, support_imp = precision_recall_fscore_support(\n",
        "    np.argmax(y_test_labels, axis=1), pred_classes_improved, average=None)\n",
        "\n",
        "print(f\"{'Clase':<12} {'Base F1':<12} {'Improved F1':<12} {'Mejora':<10}\")\n",
        "print(\"=\"*50)\n",
        "for i, class_name in enumerate(class_names):\n",
        "    mejora = (f1_imp[i] - f1_base[i]) * 100\n",
        "    print(f\"{class_name:<12} {f1_base[i]:<12.3f} {f1_imp[i]:<12.3f} {mejora:>6.1f}%\")\n",
        "\n",
        "# Guardar modelos\n",
        "model_improved.save('autoencoder_improved_conservative.h5')\n",
        "decoder_classifier_improved.save('classifier_improved_conservative.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Comparación final de resultados\n",
        "print(\"=\"*60)\n",
        "print(\"COMPARACIÓN FINAL DE RESULTADOS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"BASELINE MODEL:\")\n",
        "print(f\"  - Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"  - Final training loss: {history.history['loss'][-1]:.4f}\")\n",
        "print(f\"  - Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n",
        "print(f\"  - Classifier val accuracy: {history_clf.history['val_acc'][-1]:.4f}\")\n",
        "\n",
        "print(f\"\\nIMPROVED MODEL:\")\n",
        "print(f\"  - Accuracy: {accuracy_improved:.4f} ({accuracy_improved*100:.2f}%)\")\n",
        "print(f\"  - Final training loss: {history_improved.history['loss'][-1]:.4f}\")\n",
        "print(f\"  - Final validation loss: {history_improved.history['val_loss'][-1]:.4f}\")\n",
        "print(f\"  - Classifier val accuracy: {history_clf_improved.history['val_acc'][-1]:.4f}\")\n",
        "\n",
        "mejora_porcentual = ((accuracy_improved - accuracy) / accuracy) * 100\n",
        "print(f\"\\nMEJORA EN ACCURACY: {(accuracy_improved-accuracy)*100:.2f} puntos porcentuales\")\n",
        "print(f\"MEJORA PORCENTUAL: {mejora_porcentual:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IH_fyWQnjpoJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}